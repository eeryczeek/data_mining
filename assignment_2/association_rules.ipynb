{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('datasets/ml-latest-small/movies.csv')\n",
    "genres = movies['genres'].str.split('|', expand=True)\n",
    "\n",
    "# One-hot encoding for genres\n",
    "unique_genres = genres.stack().unique()\n",
    "\n",
    "# create a column for each genre with true or false\n",
    "genres = pd.get_dummies(genres, prefix='', prefix_sep='').groupby(level=0).sum()\n",
    "\n",
    "# extract date from title (from the last bracket)\n",
    "movies['year'] = movies['title'].str.extract('.*\\\\((.*)\\\\).*', expand=True)\n",
    "movies['year'] = pd.to_numeric(movies['year'], errors='coerce')\n",
    "\n",
    "movies['year'] = movies['year'].apply(lambda x: 0 if np.isnan(x) else x)\n",
    "\n",
    "# binarize date column\n",
    "date = pd.DataFrame()\n",
    "date['movieId'] = movies['movieId']\n",
    "date = date.set_index('movieId')\n",
    "\n",
    "date['NaN'] = movies['year'].astype(int).apply(lambda x: x == 0)\n",
    "date['1900-1920'] = movies['year'].astype(int).apply(lambda x: x >= 1900 and x < 1920)\n",
    "date['1920-1940'] = movies['year'].astype(int).apply(lambda x: x >= 1920 and x < 1940)\n",
    "date['1940-1960'] = movies['year'].astype(int).apply(lambda x: x >= 1940 and x < 1960)\n",
    "date['1960-1980'] = movies['year'].astype(int).apply(lambda x: x >= 1960 and x < 1980)\n",
    "date['1980-2000'] = movies['year'].astype(int).apply(lambda x: x >= 1980 and x < 2000)\n",
    "date['2020-2040'] = movies['year'].astype(int).apply(lambda x: x >= 2020)\n",
    "\n",
    "movies = movies.drop('genres', axis=1).join(genres)\n",
    "movies = movies.drop('title', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('datasets/ml-latest-small/ratings.csv')\n",
    "\n",
    "# generate time of day from timestamp\n",
    "ratings['timestamp'] = pd.to_datetime(ratings['timestamp'], unit='s')\n",
    "\n",
    "ratings['hour'] = ratings['timestamp'].dt.hour\n",
    "ratings.drop('timestamp', axis=1, inplace=True)\n",
    "\n",
    "# one-hot from hour column\n",
    "ratings = pd.get_dummies(ratings, prefix='', prefix_sep='').groupby(level=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       antecedents     consequents  antecedent support  \\\n",
      "0                      (Adventure)        (Action)            0.128911   \n",
      "25          (Adventure, 1980-2000)        (Action)            0.071058   \n",
      "27               (Adventure, high)        (Action)            0.060509   \n",
      "16                         (Drama)       (Romance)            0.051423   \n",
      "19                         (Drama)       (evening)            0.051423   \n",
      "..                             ...             ...                 ...   \n",
      "71              (Drama, 1980-2000)         (Crime)            0.027104   \n",
      "93              (Drama, 1980-2000)  (high, Comedy)            0.027104   \n",
      "39              (Drama, 1980-2000)        (Comedy)            0.027104   \n",
      "24           (Adventure, Thriller)        (Action)            0.026886   \n",
      "90  (Adventure, medium, 1980-2000)        (Action)            0.026270   \n",
      "\n",
      "    consequent support   support  confidence       lift  leverage  conviction  \\\n",
      "0             0.285824  0.128911    1.000000   3.498653  0.092065         inf   \n",
      "25            0.285824  0.071058    1.000000   3.498653  0.050748         inf   \n",
      "27            0.285824  0.060509    1.000000   3.498653  0.043214         inf   \n",
      "16            0.070198  0.043531    0.846519  12.058944  0.039921    6.058073   \n",
      "19            0.327725  0.056159    1.092089   3.332331  0.039306         inf   \n",
      "..                 ...       ...         ...        ...       ...         ...   \n",
      "71            0.075473  0.030441    1.123106  14.880917  0.028395         inf   \n",
      "93            0.027925  0.028131    1.037879  37.166172  0.027374         inf   \n",
      "39            0.033444  0.050936    1.879261  56.191790  0.050029         inf   \n",
      "24            0.285824  0.026886    1.000000   3.498653  0.019201         inf   \n",
      "90            0.285824  0.026270    1.000000   3.498653  0.018761         inf   \n",
      "\n",
      "    zhangs_metric  \n",
      "0        0.819865  \n",
      "25       0.768806  \n",
      "27       0.760173  \n",
      "16       0.966789  \n",
      "19       0.737853  \n",
      "..            ...  \n",
      "71       0.958787  \n",
      "93       1.000203  \n",
      "39       1.009567  \n",
      "24       0.733907  \n",
      "90       0.733443  \n",
      "\n",
      "[97 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "#combine movies with ratings on movieId\n",
    "df = pd.merge(movies, ratings, on='movieId')\n",
    "df = pd.merge(df, date, on='movieId')\n",
    "\n",
    "# one hot encode the ratings\n",
    "df['low'] = np.where(df['rating'] <= 2, True, False)\n",
    "df['medium'] = np.where((df['rating'] > 2) & (df['rating'] < 4), True, False)\n",
    "df['high'] = np.where(df['rating'] >= 4, True, False)\n",
    "\n",
    "# one hot encode the hours\n",
    "df['morning'] = np.where((df['hour'] >= 6) & (df['hour'] < 12), True, False)\n",
    "df['afternoon'] = np.where((df['hour'] >= 12) & (df['hour'] < 18), True, False)\n",
    "df['evening'] = np.where((df['hour'] >= 18) & (df['hour'] < 24), True, False)\n",
    "df['night'] = np.where((df['hour'] >= 0) & (df['hour'] < 6), True, False)\n",
    "\n",
    "#drop hour and userId columns\n",
    "df.drop('userId', axis=1, inplace=True)\n",
    "df.drop('hour', axis=1, inplace=True)\n",
    "\n",
    "#drop rating column and movieId column\n",
    "df.drop('rating', axis=1, inplace=True)\n",
    "df.drop('movieId', axis=1, inplace=True)\n",
    "df.drop('year', axis=1, inplace=True)\n",
    "\n",
    "# Create frequent itemsets using the apriori algorithm\n",
    "df.dropna(inplace=True)\n",
    "df.fillna(0, inplace=True)\n",
    "df = df.astype(bool)\n",
    "\n",
    "#drop rows where df['NaN'] is true\n",
    "df = df[df['NaN'] == False]\n",
    "df.drop('NaN', axis=1, inplace=True)\n",
    "\n",
    "frequent_itemsets = apriori(df, min_support=0.024, use_colnames=True)\n",
    "\n",
    "# create the rules using support metric\n",
    "rules = association_rules(frequent_itemsets)\n",
    "\n",
    "# order the rules by antecedent support descending\n",
    "rules = rules.sort_values('antecedent support', ascending=False)\n",
    "\n",
    "# output csv with rules\n",
    "rules.to_csv('rules.csv', sep='\\t', index=False)\n",
    "print(rules)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
