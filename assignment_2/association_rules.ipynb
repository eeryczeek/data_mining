{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('datasets/ml-latest-small/movies.csv')\n",
    "genres = movies['genres'].str.split('|', expand=True)\n",
    "\n",
    "# One-hot encoding for genres\n",
    "unique_genres = genres.stack().unique()\n",
    "\n",
    "# create a column for each genre with true or false\n",
    "genres = pd.get_dummies(genres, prefix='', prefix_sep='').groupby(level=0).sum()\n",
    "\n",
    "# extract date from title (from the last bracket)\n",
    "movies['year'] = movies['title'].str.extract('.*\\\\((.*)\\\\).*', expand=True)\n",
    "movies['year'] = pd.to_numeric(movies['year'], errors='coerce')\n",
    "\n",
    "movies['year'] = movies['year'].apply(lambda x: 0 if np.isnan(x) else x)\n",
    "\n",
    "# binarize date column\n",
    "date = pd.DataFrame()\n",
    "date['movieId'] = movies['movieId']\n",
    "date = date.set_index('movieId')\n",
    "\n",
    "date['NaN'] = movies['year'].astype(int).apply(lambda x: x == 0)\n",
    "date['1900-1920'] = movies['year'].astype(int).apply(lambda x: x >= 1900 and x < 1920)\n",
    "date['1920-1940'] = movies['year'].astype(int).apply(lambda x: x >= 1920 and x < 1940)\n",
    "date['1940-1960'] = movies['year'].astype(int).apply(lambda x: x >= 1940 and x < 1960)\n",
    "date['1960-1980'] = movies['year'].astype(int).apply(lambda x: x >= 1960 and x < 1980)\n",
    "date['1980-2000'] = movies['year'].astype(int).apply(lambda x: x >= 1980 and x < 2000)\n",
    "date['2020-2040'] = movies['year'].astype(int).apply(lambda x: x >= 2020)\n",
    "\n",
    "movies = movies.drop('genres', axis=1).join(genres)\n",
    "movies = movies.drop('title', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('datasets/ml-latest-small/ratings.csv')\n",
    "\n",
    "# generate time of day from timestamp\n",
    "ratings['timestamp'] = pd.to_datetime(ratings['timestamp'], unit='s')\n",
    "\n",
    "ratings['hour'] = ratings['timestamp'].dt.hour\n",
    "ratings.drop('timestamp', axis=1, inplace=True)\n",
    "\n",
    "# one-hot from hour column\n",
    "ratings = pd.get_dummies(ratings, prefix='', prefix_sep='').groupby(level=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             antecedents           consequents  \\\n",
      "0                            (Adventure)              (Action)   \n",
      "25                (1980-2000, Adventure)              (Action)   \n",
      "27               (High Score, Adventure)              (Action)   \n",
      "16                               (Drama)             (Romance)   \n",
      "42                               (Drama)   (1980-2000, Comedy)   \n",
      "..                                   ...                   ...   \n",
      "71                    (1980-2000, Drama)               (Crime)   \n",
      "94                    (1980-2000, Drama)  (High Score, Comedy)   \n",
      "40                    (1980-2000, Drama)              (Comedy)   \n",
      "24                 (Adventure, Thriller)              (Action)   \n",
      "90  (1980-2000, Adventure, Medium Score)              (Action)   \n",
      "\n",
      "    antecedent support  consequent support   support  confidence       lift  \\\n",
      "0             0.128911            0.285824  0.128911    1.000000   3.498653   \n",
      "25            0.071058            0.285824  0.071058    1.000000   3.498653   \n",
      "27            0.060509            0.285824  0.060509    1.000000   3.498653   \n",
      "16            0.051423            0.070198  0.043531    0.846519  12.058944   \n",
      "42            0.051423            0.046123  0.050936    0.990517  21.475524   \n",
      "..                 ...                 ...       ...         ...        ...   \n",
      "71            0.027104            0.075473  0.030441    1.123106  14.880917   \n",
      "94            0.027104            0.027925  0.028131    1.037879  37.166172   \n",
      "40            0.027104            0.033444  0.050936    1.879261  56.191790   \n",
      "24            0.026886            0.285824  0.026886    1.000000   3.498653   \n",
      "90            0.026270            0.285824  0.026270    1.000000   3.498653   \n",
      "\n",
      "    leverage  conviction  zhangs_metric  \n",
      "0   0.092065         inf       0.819865  \n",
      "25  0.050748         inf       0.768806  \n",
      "27  0.043214         inf       0.760173  \n",
      "16  0.039921    6.058073       0.966789  \n",
      "42  0.048564  100.583815       1.005122  \n",
      "..       ...         ...            ...  \n",
      "71  0.028395         inf       0.958787  \n",
      "94  0.027374         inf       1.000203  \n",
      "40  0.050029         inf       1.009567  \n",
      "24  0.019201         inf       0.733907  \n",
      "90  0.018761         inf       0.733443  \n",
      "\n",
      "[97 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "#combine movies with ratings on movieId\n",
    "df = pd.merge(movies, ratings, on='movieId')\n",
    "df = pd.merge(df, date, on='movieId')\n",
    "\n",
    "# one hot encode the ratings\n",
    "df['Low Score'] = np.where(df['rating'] <= 2, True, False)\n",
    "df['Medium Score'] = np.where((df['rating'] > 2) & (df['rating'] < 4), True, False)\n",
    "df['High Score'] = np.where(df['rating'] >= 4, True, False)\n",
    "\n",
    "# one hot encode the hours\n",
    "df['Morning'] = np.where((df['hour'] >= 6) & (df['hour'] < 12), True, False)\n",
    "df['Afternoon'] = np.where((df['hour'] >= 12) & (df['hour'] < 18), True, False)\n",
    "df['Evening'] = np.where((df['hour'] >= 18) & (df['hour'] < 24), True, False)\n",
    "df['Night'] = np.where((df['hour'] >= 0) & (df['hour'] < 6), True, False)\n",
    "\n",
    "#drop useless columns\n",
    "df.drop('userId', axis=1, inplace=True)\n",
    "df.drop('hour', axis=1, inplace=True)\n",
    "df.drop('rating', axis=1, inplace=True)\n",
    "df.drop('movieId', axis=1, inplace=True)\n",
    "df.drop('year', axis=1, inplace=True)\n",
    "\n",
    "# Create frequent itemsets using the apriori algorithm\n",
    "df.dropna(inplace=True)\n",
    "df.fillna(0, inplace=True)\n",
    "df = df.astype(bool)\n",
    "\n",
    "#drop rows where df['NaN'] is true\n",
    "df = df[df['NaN'] == False]\n",
    "df.drop('NaN', axis=1, inplace=True)\n",
    "\n",
    "frequent_itemsets = apriori(df, min_support=0.024, use_colnames=True)\n",
    "\n",
    "# create the rules using support metric\n",
    "rules = association_rules(frequent_itemsets)\n",
    "\n",
    "# order the rules by antecedent support descending\n",
    "rules = rules.sort_values('antecedent support', ascending=False)\n",
    "\n",
    "# output csv with rules\n",
    "rules.to_csv('rules.csv', sep='\\t', index=False)\n",
    "print(rules)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
